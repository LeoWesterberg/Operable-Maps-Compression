{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of datasets + stats for compressing with FPDE\n",
    "This notebook contains methods for passing a .shp-file (or directory) and obtaining stats for the FPDE properties of the compression. Stats include the number of chunks, number of deltas within each chunk, average number of vertices, and a distribution of the overhead within the format."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating one shape-file\n",
    "The methods take one .shp-file and return the stats. Multiple calls can be merged further done if a set of .shp-files are to be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import glob\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import tqdm\n",
    "import shapely\n",
    "import random\n",
    "import os\n",
    "from shapely.wkt import loads\n",
    "from algos.fpd_extended_lib.cfg import *\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from algos.alg_fpd_extended import FpdExtended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entries: 25885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25884/25884 [00:00<00:00, 141248.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex count (avg, min, max): 13.72, 2, 448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#df = gpd.read_file('data/ne_10m_admin_1_states_provinces.shp')\n",
    "#df = gpd.read_file('data/sweden-latest-free/gis_osm_buildings_a_free_1.shp')\n",
    "#df = gpd.read_file('data/sweden-latest-free/gis_osm_natural_a_free_1.shp')\n",
    "df = gpd.read_file('data/sweden-latest-free/gis_osm_railways_free_1.shp')\n",
    "\n",
    "MAX_ITER = -1\n",
    "ONLY_VERTEX_CNT = True # Can be used if only the amount of vertices in the dataset is required\n",
    "\n",
    "df = df[df.type != \"Point\"]\n",
    "print(\"Count of entries:\", len(df))\n",
    "shapes = df.geometry\n",
    "\n",
    "vertex_cnt = []\n",
    "if ONLY_VERTEX_CNT:\n",
    "    for s in tqdm.tqdm(shapes[0:MAX_ITER]):\n",
    "        vertex_cnt.append(shapely.get_num_coordinates(s))\n",
    "\n",
    "    print(\"Vertex count (avg, min, max): \" + str(round(np.average(vertex_cnt), 2)), np.min(vertex_cnt), np.max(vertex_cnt), sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25884/25884 [01:18<00:00, 330.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- AVERAGE COMPRESSED SHAPE ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No Comp Size           228.54\n",
       "Comp Size              109.59\n",
       "Comp Factor              1.64\n",
       "Vertex Cnt              13.72\n",
       "Chunk Cnt                1.66\n",
       "Avg Vertices in Chk      6.67\n",
       "Min Vertices in Chk      5.24\n",
       "Max Vertices in Chk      7.85\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global: Min Vertices in Chk / Max Vertices in Chk 1.0 16.0\n",
      "---- DATA DISTRIBUTION ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Global Header Bitsize       396.84\n",
       "Chk Deltas Cnt Bitsize        8.31\n",
       "Full Coordinates Bitsize    106.42\n",
       "Deltas Bitsize              361.15\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Global Header Bitsize       45.47\n",
       "Chk Deltas Cnt Bitsize       0.95\n",
       "Full Coordinates Bitsize    12.19\n",
       "Deltas Bitsize              41.38\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- TO SET MANUAL PARAMS ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chk Deltas Cnt Max         15\n",
       "Bits Chk Deltas Cnt Max     4\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = pd.DataFrame(columns=[\"No Comp Size\", \"Comp Size\", \"Comp Factor\", \"Vertex Cnt\", \"Chunk Cnt\", \"Avg Vertices in Chk\", \"Min Vertices in Chk\", \"Max Vertices in Chk\"])\n",
    "stats_distribution = pd.DataFrame()\n",
    "stats_max_values = pd.DataFrame()\n",
    "alg = FpdExtended()\n",
    "\n",
    "for idx, s in enumerate(tqdm.tqdm(shapes[0:MAX_ITER])):\n",
    "    bin = alg.compress(s)[1]\n",
    "    wkb_len = len(shapely.to_wkb(s))\n",
    "    bin_len = len(bin)\n",
    "    coords_len = shapely.get_num_coordinates(s)\n",
    "\n",
    "    chks, _, overhead_stats = alg.get_chunks(bin, include_ring_start=False, verbose=True)\n",
    "    chk_cnt = len(chks)\n",
    "    chk_lens = list(map(lambda x: len(x), chks))\n",
    "\n",
    "    stats.loc[len(stats)] = [wkb_len, bin_len, wkb_len / bin_len, coords_len, chk_cnt, np.average(chk_lens), np.min(chk_lens), np.max(chk_lens)]\n",
    "\n",
    "    # Analysis of space\n",
    "    max_values, distrb = overhead_stats\n",
    "    theoretical_size = sum(distrb.values())\n",
    "    distrb = pd.DataFrame(distrb, index=[idx])\n",
    "    stats_distribution = pd.concat([stats_distribution, distrb])\n",
    "    stats_max_values = pd.concat([stats_max_values, pd.DataFrame(max_values, index=[idx])])\n",
    "\n",
    "    DISPLAY_PER_SHAPE_STATS = False\n",
    "    if DISPLAY_PER_SHAPE_STATS:\n",
    "        display(distrb)\n",
    "        print(\"Size (calculated, rounded to byte, real):\", theoretical_size, f\"({((theoretical_size + 7) & (-8))})\", bin_len * 8)\n",
    "        print(\"Max Values:\", dict(max_values))\n",
    "\n",
    "print(\"---- AVERAGE COMPRESSED SHAPE ----\")\n",
    "pd.set_option('display.precision', 2)\n",
    "display(stats.mean())\n",
    "print(\"Global: Min Vertices in Chk / Max Vertices in Chk\", np.min(stats['Min Vertices in Chk']), np.max(stats['Max Vertices in Chk']))\n",
    "\n",
    "print(\"---- DATA DISTRIBUTION ----\")\n",
    "final_distribution = stats_distribution.mean()\n",
    "display(final_distribution)\n",
    "display(final_distribution.apply(lambda x: 100 * x / sum(final_distribution)))\n",
    "\n",
    "print(\"---- TO SET MANUAL PARAMS ----\")\n",
    "final_max_values = stats_max_values.max()\n",
    "min_bits = final_max_values.apply(lambda x: required_bits(x))\n",
    "min_bits = min_bits.add_prefix(\"Bits \")\n",
    "display(pd.concat([final_max_values, min_bits]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
